Configurations
===========================================
{'batch_size': 50,
 'bf_search_max': 400.0,
 'bf_search_min': -400.0,
 'bf_search_step_size': 1.0,
 'dataset': 'machine-1-2',
 'dense_dim': 500,
 'early_stop': True,
 'get_score_on_dim': False,
 'gradient_clip_norm': 10.0,
 'initial_lr': 0.001,
 'l2_reg': 0.0001,
 'level': 0.01,
 'lr_anneal_epoch_freq': 40,
 'lr_anneal_factor': 0.5,
 'lr_anneal_step_freq': None,
 'max_epoch': 10,
 'max_test_size': None,
 'max_train_size': None,
 'nf_layers': 20,
 'posterior_flow_type': 'nf',
 'restore_dir': None,
 'result_dir': 'result',
 'rnn_cell': 'GRU',
 'rnn_num_hidden': 500,
 'save_dir': 'model',
 'save_z': False,
 'std_epsilon': 0.0001,
 'test_batch_size': 50,
 'test_n_z': 1,
 'test_score_filename': 'test_score.pkl',
 'test_start': 0,
 'train_score_filename': 'train_score.pkl',
 'train_start': 0,
 'use_connected_z_p': True,
 'use_connected_z_q': True,
 'valid_step_freq': 100,
 'window_length': 100,
 'x_dim': 38,
 'z_dim': 3}

load data of: machine-1-2
train:  0 None
test:  0 None
Data normalized
Data normalized
train set shape:  (23694, 38)
test set shape:  (23694, 38)
test set label shape:  (23694,)
Trainable Parameters                                            (2,607,740 in total)
------------------------------------------------------------------------------------
model/q_z_given_x/rnn_q_z/rnn/gru_cell/gates/kernel             (538, 1000)  538,000
model/q_z_given_x/rnn_q_z/rnn/gru_cell/gates/bias               (1000,)        1,000
model/q_z_given_x/rnn_q_z/rnn/gru_cell/candidate/kernel         (538, 500)   269,000
model/q_z_given_x/rnn_q_z/rnn/gru_cell/candidate/bias           (500,)           500
model/q_z_given_x/rnn_q_z/dense/kernel                          (500, 500)   250,000
model/q_z_given_x/rnn_q_z/dense/bias                            (500,)           500
model/q_z_given_x/rnn_q_z/dense_1/kernel                        (500, 500)   250,000
model/q_z_given_x/rnn_q_z/dense_1/bias                          (500,)           500
model/vae/variational/z_mean/kernel                             (503, 3)       1,509
model/vae/variational/z_mean/bias                               (3,)               3
model/vae/variational/z_std/kernel                              (503, 3)       1,509
model/vae/variational/z_std/bias                                (3,)               3
model/posterior_flow/_0/w                                       (1, 3)             3
model/posterior_flow/_0/b                                       (1,)               1
model/posterior_flow/_0/u                                       (1, 3)             3
model/posterior_flow/_1/w                                       (1, 3)             3
model/posterior_flow/_1/b                                       (1,)               1
model/posterior_flow/_1/u                                       (1, 3)             3
model/posterior_flow/_2/w                                       (1, 3)             3
model/posterior_flow/_2/b                                       (1,)               1
model/posterior_flow/_2/u                                       (1, 3)             3
model/posterior_flow/_3/w                                       (1, 3)             3
model/posterior_flow/_3/b                                       (1,)               1
model/posterior_flow/_3/u                                       (1, 3)             3
model/posterior_flow/_4/w                                       (1, 3)             3
model/posterior_flow/_4/b                                       (1,)               1
model/posterior_flow/_4/u                                       (1, 3)             3
model/posterior_flow/_5/w                                       (1, 3)             3
model/posterior_flow/_5/b                                       (1,)               1
model/posterior_flow/_5/u                                       (1, 3)             3
model/posterior_flow/_6/w                                       (1, 3)             3
model/posterior_flow/_6/b                                       (1,)               1
model/posterior_flow/_6/u                                       (1, 3)             3
model/posterior_flow/_7/w                                       (1, 3)             3
model/posterior_flow/_7/b                                       (1,)               1
model/posterior_flow/_7/u                                       (1, 3)             3
model/posterior_flow/_8/w                                       (1, 3)             3
model/posterior_flow/_8/b                                       (1,)               1
model/posterior_flow/_8/u                                       (1, 3)             3
model/posterior_flow/_9/w                                       (1, 3)             3
model/posterior_flow/_9/b                                       (1,)               1
model/posterior_flow/_9/u                                       (1, 3)             3
model/posterior_flow/_10/w                                      (1, 3)             3
model/posterior_flow/_10/b                                      (1,)               1
model/posterior_flow/_10/u                                      (1, 3)             3
model/posterior_flow/_11/w                                      (1, 3)             3
model/posterior_flow/_11/b                                      (1,)               1
model/posterior_flow/_11/u                                      (1, 3)             3
model/posterior_flow/_12/w                                      (1, 3)             3
model/posterior_flow/_12/b                                      (1,)               1
model/posterior_flow/_12/u                                      (1, 3)             3
model/posterior_flow/_13/w                                      (1, 3)             3
model/posterior_flow/_13/b                                      (1,)               1
model/posterior_flow/_13/u                                      (1, 3)             3
model/posterior_flow/_14/w                                      (1, 3)             3
model/posterior_flow/_14/b                                      (1,)               1
model/posterior_flow/_14/u                                      (1, 3)             3
model/posterior_flow/_15/w                                      (1, 3)             3
model/posterior_flow/_15/b                                      (1,)               1
model/posterior_flow/_15/u                                      (1, 3)             3
model/posterior_flow/_16/w                                      (1, 3)             3
model/posterior_flow/_16/b                                      (1,)               1
model/posterior_flow/_16/u                                      (1, 3)             3
model/posterior_flow/_17/w                                      (1, 3)             3
model/posterior_flow/_17/b                                      (1,)               1
model/posterior_flow/_17/u                                      (1, 3)             3
model/posterior_flow/_18/w                                      (1, 3)             3
model/posterior_flow/_18/b                                      (1,)               1
model/posterior_flow/_18/u                                      (1, 3)             3
model/posterior_flow/_19/w                                      (1, 3)             3
model/posterior_flow/_19/b                                      (1,)               1
model/posterior_flow/_19/u                                      (1, 3)             3
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/gates/kernel      (503, 1000)  503,000
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/gates/bias        (1000,)        1,000
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/candidate/kernel  (503, 500)   251,500
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/candidate/bias    (500,)           500
model/p_x_given_z/hidden/rnn_p_x/dense/kernel                   (500, 500)   250,000
model/p_x_given_z/hidden/rnn_p_x/dense/bias                     (500,)           500
model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel                 (500, 500)   250,000
model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                   (500,)           500
model/p_x_given_z/x_mean/kernel                                 (500, 38)     19,000
model/p_x_given_z/x_mean/bias                                   (38,)             38
model/p_x_given_z/x_std/kernel                                  (500, 38)     19,000
model/p_x_given_z/x_std/bias                                    (38,)             38

train_values: (16586, 38)
[Epoch 1/10, Step 100] step time: 0.9088s (±4.299s); train time: 47.99s; valid time: 42.92s; loss: 7.16821 (±47.3095); valid loss: -15.5832 (*)
[Epoch 1/10, Step 200] step time: 0.8729s (±4.121s); train time: 45.89s; valid time: 41.43s; loss: -26.9483 (±21.8102); valid loss: -36.6313 (*)
[Epoch 1/10, Step 300] step time: 0.8561s (±4.033s); train time: 45.08s; valid time: 40.54s; loss: -43.9916 (±2.63784); valid loss: -34.9361
train_values: (16586, 38)
[Epoch 2/10, Step 400, ETA 42m 15.28s] step time: 0.8703s (±4.149s); train time: 32.18s; valid time: 41.71s; loss: -48.5249 (±2.50584); valid loss: -45.3168 (*)
[Epoch 2/10, Step 500, ETA 40m 30.39s] step time: 0.8464s (±4s); train time: 44.43s; valid time: 40.22s; loss: -51.6675 (±2.24754); valid loss: -49.4558 (*)
[Epoch 2/10, Step 600, ETA 38m 47.13s] step time: 0.835s (±3.924s); train time: 44.08s; valid time: 39.43s; loss: -54.7348 (±2.1433); valid loss: -53.4025 (*)
train_values: (16586, 38)
[Epoch 3/10, Step 700, ETA 37m 6.436s] step time: 0.8266s (±3.883s); train time: 18.48s; valid time: 39.03s; loss: -57.5725 (±2.59259); valid loss: -54.0873 (*)
[Epoch 3/10, Step 800, ETA 35m 32.05s] step time: 0.8322s (±3.902s); train time: 44.03s; valid time: 39.23s; loss: -60.0224 (±2.54017); valid loss: -57.9842 (*)
[Epoch 3/10, Step 900, ETA 33m 56.57s] step time: 0.8189s (±3.819s); train time: 43.54s; valid time: 38.37s; loss: -63.0979 (±2.23686); valid loss: -56.2238
train_values: (16586, 38)
[Epoch 4/10, Step 1000, ETA 32m 25.66s] step time: 0.8271s (±3.859s); train time: 5.697s; valid time: 38.81s; loss: -65.457 (±2.65589); valid loss: -60.8979 (*)
[Epoch 4/10, Step 1100, ETA 30m 57.38s] step time: 0.8328s (±3.922s); train time: 43.9s; valid time: 39.4s; loss: -67.0327 (±2.2693); valid loss: -64.525 (*)
[Epoch 4/10, Step 1200, ETA 29m 28.69s] step time: 0.8257s (±3.806s); train time: 44.33s; valid time: 38.26s; loss: -68.1436 (±2.99216); valid loss: -63.6608
[Epoch 4/10, Step 1300, ETA 28m 3.085s] step time: 0.8397s (±3.999s); train time: 43.81s; valid time: 40.18s; loss: -69.1952 (±2.06913); valid loss: -65.22 (*)
train_values: (16586, 38)
[Epoch 5/10, Step 1400, ETA 26m 38.73s] step time: 0.8472s (±4.013s); train time: 37.33s; valid time: 40.34s; loss: -69.7337 (±3.43157); valid loss: -67.0998 (*)
[Epoch 5/10, Step 1500, ETA 25m 13.82s] step time: 0.843s (±4.02s); train time: 43.9s; valid time: 40.42s; loss: -69.0201 (±4.93893); valid loss: -68.2411 (*)
[Epoch 5/10, Step 1600, ETA 23m 49.79s] step time: 0.8508s (±4.029s); train time: 44.55s; valid time: 40.53s; loss: -69.3833 (±4.42625); valid loss: -69.5387 (*)
train_values: (16586, 38)
[Epoch 6/10, Step 1700, ETA 22m 25s] step time: 0.8439s (±3.956s); train time: 24.69s; valid time: 39.75s; loss: -69.6036 (±3.90239); valid loss: -61.0484
[Epoch 6/10, Step 1800, ETA 20m 59.89s] step time: 0.8396s (±3.904s); train time: 44.72s; valid time: 39.25s; loss: -70.1755 (±3.43995); valid loss: -61.0838
[Epoch 6/10, Step 1900, ETA 19m 34.77s] step time: 0.8376s (±3.894s); train time: 44.67s; valid time: 39.11s; loss: -69.893 (±4.94973); valid loss: -62.4686
train_values: (16586, 38)
[Epoch 7/10, Step 2000, ETA 18m 9.341s] step time: 0.8308s (±3.888s); train time: 11.31s; valid time: 39.1s; loss: -70.6837 (±3.21405); valid loss: -59.9598
[Epoch 7/10, Step 2100, ETA 16m 43.54s] step time: 0.8205s (±3.82s); train time: 43.68s; valid time: 38.38s; loss: -70.7761 (±3.423); valid loss: -61.7301
[Epoch 7/10, Step 2200, ETA 15m 18.19s] step time: 0.8225s (±3.854s); train time: 43.54s; valid time: 38.72s; loss: -70.9689 (±4.88578); valid loss: -63.1797
[Epoch 7/10, Step 2300, ETA 13m 53.22s] step time: 0.8252s (±3.857s); train time: 43.78s; valid time: 38.76s; loss: -70.9482 (±2.8339); valid loss: -69.3975
train_values: (16586, 38)
[Epoch 8/10, Step 2400, ETA 12m 28.62s] step time: 0.8296s (±3.876s); train time: 42.74s; valid time: 38.93s; loss: -71.7113 (±3.14853); valid loss: -68.3908
[Epoch 8/10, Step 2500, ETA 11m 4.133s] step time: 0.8292s (±3.847s); train time: 44.25s; valid time: 38.69s; loss: -72.1734 (±2.82182); valid loss: -69.2441
[Epoch 8/10, Step 2600, ETA 9m 39.93s] step time: 0.8354s (±3.905s); train time: 44.32s; valid time: 39.24s; loss: -72.1974 (±3.54052); valid loss: -69.9085 (*)
train_values: (16586, 38)
[Epoch 9/10, Step 2700, ETA 8m 15.66s] step time: 0.8299s (±3.848s); train time: 30.36s; valid time: 38.68s; loss: -72.5209 (±3.23597); valid loss: -65.3586
[Epoch 9/10, Step 2800, ETA 6m 51.65s] step time: 0.8395s (±3.983s); train time: 43.98s; valid time: 39.99s; loss: -72.6407 (±3.18375); valid loss: -68.8711
[Epoch 9/10, Step 2900, ETA 5m 27.78s] step time: 0.8497s (±4.015s); train time: 44.65s; valid time: 40.38s; loss: -73.0685 (±3.44127); valid loss: -62.7791
train_values: (16586, 38)
[Epoch 10/10, Step 3000, ETA 4m 3.789s] step time: 0.8465s (±4.034s); train time: 17.27s; valid time: 40.52s; loss: -73.1201 (±2.81591); valid loss: -70.2387 (*)
[Epoch 10/10, Step 3100, ETA 2m 39.73s] step time: 0.841s (±3.999s); train time: 43.91s; valid time: 40.2s; loss: -73.5091 (±2.88518); valid loss: -70.0774
[Epoch 10/10, Step 3200, ETA 1m 15.69s] step time: 0.8497s (±4.067s); train time: 44.14s; valid time: 40.85s; loss: -73.7801 (±2.33261); valid loss: -68.886
------------------------------ testing ------------------------------
search range:  -400.0 400.0
cur thr:  -399.0 [0.8316172233173325, 0.9374999782986116, 0.7472324585381466, 405.0, 23026.0, 27.0, 137.0, 15.624804689941376] [0.8316172233173325, 0.9374999782986116, 0.7472324585381466, 405.0, 23026.0, 27.0, 137.0, 15.624804689941376] -399.0
cur thr:  -349.0 [0.8307642762476201, 0.935334851377948, 0.7472324585381466, 405.0, 23025.0, 28.0, 137.0, 4.249946875664055] [0.8316172233173325, 0.9374999782986116, 0.7472324585381466, 405.0, 23026.0, 27.0, 137.0, 15.624804689941376] -399.0
cur thr:  -299.0 [0.9012413950742088, 0.9381237337699854, 0.8671586555874787, 470.0, 23022.0, 31.0, 72.0, 3.7777358029355232] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  -249.0 [0.8926825467605319, 0.9197651483411908, 0.8671586555874787, 470.0, 23012.0, 41.0, 72.0, 3.7777358029355232] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  -199.0 [0.8851173960510749, 0.9038461364644974, 0.8671586555874787, 470.0, 23003.0, 50.0, 72.0, 3.7777358029355232] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  -149.0 [0.8592271602415177, 0.8514492599375134, 0.8671586555874787, 470.0, 22971.0, 82.0, 72.0, 3.7777358029355232] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  -99.0 [0.8289191573884588, 0.7939189055081266, 0.8671586555874787, 470.0, 22931.0, 122.0, 72.0, 3.7777358029355232] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  -49.0 [0.7709767591330482, 0.6273148075542267, 0.9999999815498158, 542.0, 22731.0, 322.0, 0.0, 4.4999550004499955] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  1.0 [0.6732874508224076, 0.5074906319523349, 0.9999999815498158, 542.0, 22527.0, 526.0, 0.0, 2.7999720002799973] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  51.0 [0.47481021640723964, 0.3113153342256443, 0.9999999815498158, 542.0, 21854.0, 1199.0, 0.0, 2.299977000229998] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  101.0 [0.04490986463185329, 0.022970968415778358, 0.9999999815498158, 542.0, 0.0, 23053.0, 0.0, 0.0] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  151.0 [0.04490986463185329, 0.022970968415778358, 0.9999999815498158, 542.0, 0.0, 23053.0, 0.0, 0.0] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  201.0 [0.04490986463185329, 0.022970968415778358, 0.9999999815498158, 542.0, 0.0, 23053.0, 0.0, 0.0] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  251.0 [0.04490986463185329, 0.022970968415778358, 0.9999999815498158, 542.0, 0.0, 23053.0, 0.0, 0.0] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  301.0 [0.04490986463185329, 0.022970968415778358, 0.9999999815498158, 542.0, 0.0, 23053.0, 0.0, 0.0] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
cur thr:  351.0 [0.04490986463185329, 0.022970968415778358, 0.9999999815498158, 542.0, 0.0, 23053.0, 0.0, 0.0] [0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
[0.9029728970701715, 0.9418837486596444, 0.8671586555874787, 470.0, 23024.0, 29.0, 72.0, 3.7777358029355232] -318.0
Initial threshold : 116.941795
Number of peaks : 235
Grimshaw maximum log-likelihood estimation ... [done]
	gamma = 0
	sigma = 197.21526
	L = 1476.8095132179171
Extreme quantile (probability = 0.001): 570.2510572986707
254
23595
POT result:  (0.8422888958557391, 0.8188153167453778, 0.8671586555874787, 470.0, 22949.0, 104.0, 72.0) -120.74578915569074 3.7777358029355232
==============================result==============================
{'FN': 72.0,
 'FP': 29.0,
 'TN': 23024.0,
 'TP': 470.0,
 'best-f1': 0.9029728970701715,
 'best_valid_loss': -70.23871212178075,
 'latency': 3.7777358029355232,
 'pot-FN': 72.0,
 'pot-FP': 104.0,
 'pot-TN': 22949.0,
 'pot-TP': 470.0,
 'pot-f1': 0.8422888958557391,
 'pot-latency': 3.7777358029355232,
 'pot-precision': 0.8188153167453778,
 'pot-recall': 0.8671586555874787,
 'pot-threshold': -120.74578915569074,
 'precision': 0.9418837486596444,
 'pred_time': 0.39528003941148016,
 'pred_total_time': 186.6347301006317,
 'recall': 0.8671586555874787,
 'threshold': -318.0,
 'train_time': 273.2473870038986,
 'valid_time': 0.2795183806026236}
