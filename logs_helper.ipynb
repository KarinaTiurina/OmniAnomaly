{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to parse loss and valid loss from the logs after the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = [236.365, -111.684, -120.278, -131.061, -141.938, -139.113, -138.087, -144.552, -145.022, -149.25, -147.92, -149.475, -150.614, -136.639, -136.829, -124.106, -97.5222, -141.896, -125.584, -143.088, -150.369, -158.777, -164.921, -161.699, -165.504, -165.038, -164.436, -170.233, -170.426, -171.848, -169.983, -169.411, -169.201, -175.103, -174.09, -172.813, -174.471, -176.204, -175.834, -175.381, -174.148, -176.11, -176.935, -178.575, -173.132, -177.86, -179.479, -180.71, -178.346, -180.314, -182.754, -177.441, -178.835, -182.124, -180.179, -180.67, -181.704, -180.033, -183.174, -178.438, -180.349, -184.164, -181.529, -181.11, -182.368, -183.671, -185.11, -180.376, -182.959, -183.38, -180.512, -181.033, -184.394, -186.397, -183.597, -184.409, -186.222, -182.353, -182.398, -182.758, -186.536]\n",
      "valid_loss = [-113.932, -114.159, -137.402, -137.905, -136.71, -121.741, -149.518, -145.694, -151.129, -156.256, -151.946, -153.66, -152.516, -146.188, -131.013, -142.764, -140.761, -145.711, -140.25, -135.637, -165.778, -163.865, -173.257, -169.716, -166.52, -166.5, -174.115, -174.892, -158.406, -170.946, -165.445, -166.44, -172.947, -175.804, -177.23, -179.992, -187.353, -178.317, -177.278, -176.865, -178.076, -180.515, -175.369, -182.185, -181.782, -181.402, -179.722, -184.323, -186.871, -185.986, -182.335, -183.447, -181.204, -197.313, -182.032, -185.663, -180.651, -172.243, -185.971, -187.186, -176.502, -187.296, -176.538, -188.01, -183.738, -185.266, -188.187, -190.572, -157.439, -181.086, -181.167, -190.256, -191.375, -182.635, -188.151, -192.291, -180.736, -181.252, -184.541, -186.591, -176.996]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "folder = 'result'\n",
    "\n",
    "logs_file = f'{folder}/logs.txt'\n",
    "\n",
    "\n",
    "# Initialize empty lists to store the loss and valid loss values\n",
    "loss = []\n",
    "valid_loss = []\n",
    "\n",
    "# Define the regular expression pattern to match the lines of interest\n",
    "pattern = r\"\\[Epoch \\d+/\\d+, Step \\d+(, ETA [\\d\\w\\s:.]+)?\\] .*? loss: ([\\-\\d.]+) .*? valid loss: ([\\-\\d.]+)\"\n",
    "\n",
    "# Open the logs.txt file and read line by line\n",
    "with open(logs_file, 'rb') as file:\n",
    "    for line in file:\n",
    "        encoded = line.decode('utf-8', errors='ignore')\n",
    "        # Check if the line matches the pattern\n",
    "        match = re.search(pattern, encoded)\n",
    "        if match:\n",
    "            # Extract the loss and valid loss values\n",
    "            loss_value = float(match.group(2))\n",
    "            valid_loss_value = float(match.group(3))\n",
    "            # Append the values to the respective lists\n",
    "            loss.append(loss_value)\n",
    "            valid_loss.append(valid_loss_value)\n",
    "\n",
    "# Print the results\n",
    "print(\"loss =\", loss)\n",
    "print(\"valid_loss =\", valid_loss)\n",
    "\n",
    "loss_df = pd.DataFrame(loss, columns=[\"loss\"])\n",
    "valid_loss_df = pd.DataFrame(valid_loss, columns=[\"valid_loss\"])\n",
    "\n",
    "loss_df.to_csv(f'{folder}/training_loss.csv', index=False)\n",
    "valid_loss_df.to_csv(f'{folder}/training_valid_loss.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
